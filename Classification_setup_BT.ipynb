{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_setup_BT",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhardwaj1230/NMT/blob/master/Classification_setup_BT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-18Scsxi9pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('./data/test/sampleAnnotation.tsv', header=None)\n",
        "\n",
        "new_l=[]\n",
        "for item in data[0]:\n",
        "    if item == 1.0:\n",
        "        new_l.append(item)\n",
        "    else:\n",
        "        new_l.append('0')\n",
        "\n",
        "        \n",
        "with open('test_annotaion', 'w') as w:\n",
        "    [w.write(item+'\\n') for item in new_l]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw-st9V1iQmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "with open('./data/train/NO_Problematic/extracted.en','r') as r:\n",
        "    no_prob_en = [item.strip('\\n') for item in tqdm(r.readlines())]\n",
        "\n",
        "with open('./data/train/NO_Problematic/extracted.fr','r') as r:\n",
        "    no_prob_fr = [item.strip('\\n') for item in tqdm(r.readlines())]\n",
        "\n",
        "with open('./data/train/Problematic/extracted.en','r') as r:\n",
        "    prob_en = [item.strip('\\n') for item in tqdm(r.readlines())]\n",
        "\n",
        "with open('./data/train/Problematic/extracted.fr','r') as r:\n",
        "    prob_fr = [item.strip('\\n') for item in tqdm(r.readlines())]\n",
        "    \n",
        "clean_en=[]\n",
        "clean_fr=[]\n",
        "\n",
        "cnt=0\n",
        "for en, fr in tqdm(zip(prob_en,prob_fr)):\n",
        "    if fr != '':\n",
        "        cnt +=1\n",
        "        clean_en.append(en)\n",
        "        clean_fr.append(fr)\n",
        "print('Cleaned : ', len(prob_en)-cnt)\n",
        "\n",
        "np_clean_en=[]\n",
        "np_clean_fr=[]\n",
        "\n",
        "cnt=0\n",
        "for en, fr in zip(no_prob_en,no_prob_fr):\n",
        "    if fr != '':\n",
        "        cnt +=1\n",
        "        np_clean_en.append(en)\n",
        "        np_clean_fr.append(fr)\n",
        "print('Cleaned : ', len(no_prob_en)-cnt)\n",
        "\n",
        "no_prob_anno = [1] * len(np_clean_en)\n",
        "prob_anno = [0] * len(clean_en)\n",
        "\n",
        "    \n",
        "train_en = np_clean_en + clean_en\n",
        "train_fr = np_clean_fr + clean_fr\n",
        "anno = no_prob_anno + prob_anno\n",
        "\n",
        "import random\n",
        "\n",
        "combined = list(set(zip(train_en, train_fr, anno)))\n",
        "random.shuffle(combined)\n",
        "train_en, train_fr, anno = zip(*combined)\n",
        "combined = 0 \n",
        "\n",
        "with open('./data/train/train_en', 'w') as w:\n",
        "    [w.write(item+'\\n') for item in train_en]\n",
        "    \n",
        "with open('./data/train/train_fr', 'w') as w:\n",
        "    [w.write(item+'\\n') for item in train_fr]\n",
        "    \n",
        "with open('./data/train/train_anno', 'w') as w:\n",
        "    [w.write(str(item)+'\\n') for item in anno]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vxum3ce1xrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "with open('./data/train/train_en') as r:\n",
        "    train_en = [item.strip('\\n').lower() for item in tqdm(r)]\n",
        "\n",
        "with open('./data/train/train_fr') as r:\n",
        "    train_fr = [item.strip('\\n').lower() for item in tqdm(r)]\n",
        "\n",
        "train_y = np.loadtxt('./data/train/train_anno', dtype='int')\n",
        "\n",
        "\n",
        "comb = list(zip(train_en,train_fr,train_y))\n",
        "comb = list(filter(lambda x : x[2] == 0, comb)) + list(filter(lambda x : x[2] == 1, comb))[0:len(list(filter(lambda x : x[2] == 0, comb)))]\n",
        "random.shuffle(comb)\n",
        "train_en, train_fr, train_y = zip(*comb)\n",
        "\n",
        "sum(train_y)/len(train_y)\n",
        "\n",
        "with open('./data/train/bal_train_en', 'w') as w:\n",
        "    [w.write(item+'\\n') for item in train_en]\n",
        "with open('./data/train/bal_train_fr', 'w') as w:\n",
        "    [w.write(item+'\\n') for item in train_fr]\n",
        "with open('./data/train/bal_train_anno', 'w') as w:\n",
        "    [w.write(str(item)+'\\n') for item in train_y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlkm8cJeA8Nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "putty tunnel: 8888 localhost:8889\n",
        "\n",
        "ssh -N -f -L localhost:8889:localhost:8886 bhardwas@octal17\n",
        "\n",
        "ssh ocatl17\n",
        "\n",
        "jupyter notebook --no-browser --port=8886"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtsEysxDA8F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/data/rali5/sans-bkp/alfonsda/workRali/004tradBureau/007corpusExtraction/noProblematic/extracted.en','r') as r:\n",
        "    no_prob_en = [item.strip('\\n') for item in r.readlines()]\n",
        "\n",
        "with open('/data/rali5/sans-bkp/alfonsda/workRali/004tradBureau/007corpusExtraction/noProblematic/extracted.fr','r') as r:\n",
        "    no_prob_fr = [item.strip('\\n') for item in r.readlines()]\n",
        "\n",
        "with open('/data/rali5/sans-bkp/alfonsda/workRali/004tradBureau/007corpusExtraction/problematic/extracted.en','r') as r:\n",
        "    prob_en = [item.strip('\\n') for item in r.readlines()]\n",
        "\n",
        "with open('/data/rali5/sans-bkp/alfonsda/workRali/004tradBureau/007corpusExtraction/problematic/extracted.fr','r') as r:\n",
        "    prob_fr = [item.strip('\\n') for item in r.readlines()]\n",
        "\n",
        "\n",
        "def join(a,b):\n",
        "    en_fr = []\n",
        "    for x,y in tqdm(zip(a,b)):\n",
        "        x = str(x)\n",
        "        y = str(y)\n",
        "        en_fr.append(' $$$$ '.join([x, y]))\n",
        "    return en_fr\n",
        "\n",
        "filter_en_fr = join(no_prob_en,no_prob_fr)\n",
        "no_prob_en=[]\n",
        "no_prob_fr=[]\n",
        "filter_en_fr = set(filter_en_fr)\n",
        "\n",
        "en_fr = join(prob_en, prob_fr)\n",
        "prob_en=[]\n",
        "prob_fr=[]\n",
        "en_fr = set(en_fr)\n",
        "\n",
        "\n",
        "clean = []\n",
        "counter = 0\n",
        "\n",
        "for to_clean in tqdm(en_fr):\n",
        "    if to_clean not in filter_en_fr :\n",
        "        clean.append(to_clean)\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter % 10 == 0:\n",
        "            print('Number of noisy records deleted :',counter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMccYqO6A7z-",
        "colab_type": "code",
        "outputId": "387545d6-755a-46b3-d22f-00b217f14dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "with open('sample.en') as r:\n",
        "    train_en = [item.strip('\\n').lower() for item in tqdm(r)]\n",
        "\n",
        "with open('sample.fr') as r:\n",
        "    train_fr = [item.strip('\\n').lower() for item in tqdm(r)]\n",
        "\n",
        "train_y = np.loadtxt('test_annotaion', dtype='int')\n",
        "\n",
        "pred = np.loadtxt('pred_annotaion_m1', dtype='int')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021it [00:00, 313220.57it/s]\n",
            "2021it [00:00, 303193.66it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN4wRr5BA7oA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=[]\n",
        "for en,fr,orig,p in zip(train_en,train_fr,train_y,pred):\n",
        "    data.append((en,fr,orig,p))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykAMaW6l8uFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(data).to_csv('datawith_pred.csv', header=None, index= False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}