{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fairseq",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhardwaj1230/NMT/blob/master/fairseq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzwYY_oa_0tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruxsFlwxWZEZ",
        "colab_type": "text"
      },
      "source": [
        "#Fairseq syntax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpgxbmNRAD5-",
        "colab_type": "text"
      },
      "source": [
        "CUDA_VISIBLE_DEVICES=1 \\\n",
        "fairseq-train data-bin/wmt14_en_fr \\\n",
        "  --lr 0.5 --clip-norm 0.1 --dropout 0.1 --max-tokens 3000 \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "  --lr-scheduler fixed --force-anneal 50 \\\n",
        "  --arch fconv_wmt_en_fr --save-dir checkpoints/fconv_wmt_en_fr \\\n",
        "  --fp16 --memory-efficient-fp16 \\\n",
        "  --log-format simple  --log-interval 100 \\\n",
        "  --user-dir ./fairseq-tensorboard/fstb \\\n",
        "  --task monitored_translation \\\n",
        "  --tensorboard-logdir /srv/gluster/users/bhardwajs/fairseq/fairseq/tensorboard_logdir\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uKV-0YuTJRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_DIR=/srv/gluster/users/bhardwajs/fairseq/fairseq/checkpoints/fconv_wmt_en_fr\n",
        "\n",
        "fairseq-interactive --path $MODEL_DIR/checkpoint_best.pt $MODEL_DIR     --beam 5 --source-lang en --target-lang fr --user-dir ./fairseq-tensorboard/fstb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKZzlwEbJ4hB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nohup fairseq-generate.py data-bin/wmt14_en_fr \\\n",
        "    --path checkpoints/fconv_wmt_en_fr/checkpoint_best.pt --batch-size 32 --beam 1 \\\n",
        "    --sampling --sampling-topk 10 --nbest 1 \\\n",
        "    --source-lang en --target-lang fr \\\n",
        "    --remove-bpe > translate_log.out &"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm4yvMg24261",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nohup fairseq-generate \\\n",
        "    data-bin/wmt14_en_fr \\\n",
        "    --path checkpoints/fconv_wmt_en_fr/checkpoint_best.pt \\\n",
        "    --beam 5 --lenpen 0.6 --remove-bpe > translate_log.out &\n",
        "\n",
        "\n",
        "nohup fairseq-generate \\\n",
        "    sample_data_NT_en-fr_2_data-bin/wmt14_en_fr \\\n",
        "    --path sample_data_NT_en-fr_2_checkpoints/fconv_wmt_en_fr/checkpoint_best.pt \\\n",
        "    --beam 5 --lenpen 0.6 --remove-bpe > translate_log.out &"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdaZb-DMJ4bS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fairseq-train data-bin/wmt14_en_fr \\\n",
        "  --lr 0.5 --clip-norm 0.1 --dropout 0.1 --max-tokens 3000 \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "  --lr-scheduler fixed --force-anneal 50 \\\n",
        "  --arch transformer_vaswani_wmt_en_fr_big --save-dir checkpoints/trans_wmt_en_fr \\\n",
        "  --fp16 --memory-efficient-fp16 \\\n",
        "  --log-format simple  --log-interval 100\n",
        "\n",
        "#################################################\n",
        "\n",
        "fairseq-train data-bin/wmt14_en_fr \\\n",
        "--arch transformer_vaswani_wmt_en_fr_big --save-dir checkpoints/trans_wmt_en_fr \\\n",
        "--optimizer adam --adam-betas '(0.9, 0.98)' \\\n",
        "--clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 \\\n",
        "--lr 0.001 --min-lr 1e-09 --dropout 0.1 \\\n",
        "--weight-decay 0.0 --criterion label_smoothed_cross_entropy \\\n",
        "--label-smoothing 0.1 --max-tokens 3000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9AnERjR3STu",
        "colab_type": "text"
      },
      "source": [
        "#Display Tensorboard:\n",
        "tensorboard --logdir=/srv/gluster/users/bhardwajs/fairseq/fairseq/tensorboard_logdir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsooGNhZ_99Y",
        "colab_type": "text"
      },
      "source": [
        "# Convert BPE to normal :\n",
        "sed 's/@@ //g' trans_result.txt > trans_result_clean.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HisWnd7WAKCd",
        "colab_type": "text"
      },
      "source": [
        "*   epoch 001 | valid on 'valid' subset | loss 3.716 | nll_loss 1.968 | ppl 3.91 | num_updates 190881\n",
        "\n",
        "*  epoch 002 | loss 3.760 | nll_loss 2.034 | ppl 4.10 | wps 15848 | ups 2 | wpb 6954.989 | bsz 187.274 | num_updates 381762 | lr 0.5 | gnorm 0.119 | clip 0.983 | oom 0.000 | loss_scale 256.000 | wall 170197 | train_wall 161576\n",
        "| epoch 002 | valid on 'valid' subset | loss 3.622 | nll_loss 1.868 | ppl 3.65 | num_updates 381762 | best_loss 3.62171\n",
        "\n",
        "*   epoch 003 | loss 3.694 | nll_loss 1.963 | ppl 3.90 | wps 15816 | ups 2 | wpb 6954.998 | bsz 187.284 | num_updates 572646 | lr 0.5 | gnorm 0.112 | clip 0.902 | oom 0.000 | loss_scale 128.000 | wall 254353 | train_wall 241933\n",
        "| epoch 003 | valid on 'valid' subset | loss 3.584 | nll_loss 1.823 | ppl 3.54 | num_updates 572646 | best_loss 3.58446\n",
        "\n",
        "*  epoch 004 | loss 3.660 | nll_loss 1.926 | ppl 3.80 | wps 15794 | ups 2 | wpb 6955.020 | bsz 187.279 | num_updates 763527 | lr 0.5 | gnorm 0.109 | clip 0.804 | oom 0.000 | loss_scale 128.000 | wall 338613 | train_wall 322259\n",
        "| epoch 004 | valid on 'valid' subset | loss 3.556 | nll_loss 1.790 | ppl 3.46 | num_updates 763527 | best_loss 3.55647\n",
        "\n",
        "\n",
        "*   epoch 005 | loss 3.639 | nll_loss 1.902 | ppl 3.74 | wps 15778 | ups 2 | wpb 6954.995 | bsz 187.283 | num_updates 954409 | lr 0.5 | gnorm 0.107 | clip 0.731 | oom 0.000 | loss_scale 256.000 | wall 422964 | train_wall 402559\n",
        "| epoch 005 | valid on 'valid' subset | loss 3.541 | nll_loss 1.767 | ppl 3.40 | num_updates 954409 | best_loss 3.54068\n",
        "\n",
        "*   epoch 006 | loss 3.623 | nll_loss 1.884 | ppl 3.69 | wps 15793 | ups 2 | wpb 6954.984 | bsz 187.285 | num_updates 1.14529e+06 | lr 0.5 | gnorm 0.106 | clip 0.676 | oom 0.000 | loss_scale 256.000 | wall 507230 | train_wall 482910\n",
        "| epoch 006 | valid on 'valid' subset | loss 3.529 | nll_loss 1.765 | ppl 3.40 | num_updates 1.14529e+06 | best_loss 3.5294\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfFuxFWSAJ_u",
        "colab_type": "text"
      },
      "source": [
        "The potential economic impact these pipelines could have on the Canadian workforce coupled with environmental concerns regarding destruction of natural habitats and pollution have brought this subject to the forefront of Canadian politics in 2013\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "As noted in uuuuu above the total cost of the prostitution consultations was $ 17722001\n",
        "\n",
        "Develop and implement a package for HIV prevention treatment and care with the aim of as close as possible to universal access to treatment for all who need it by"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPGm0p4lAJ9N",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIO3YRqlAJ6d",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RKYLz_nAJ1m",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAqbe0t4AJyl",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOVONlkFAJv9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJRYbiXXAJtV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vPf7iyAb_zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/bin/bash\n",
        "\n",
        "# Copyright (c) 2019-present, Facebook, Inc.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "set -e\n",
        "\n",
        "\n",
        "#\n",
        "# Data preprocessing configuration\n",
        "#\n",
        "CODES=60000     # number of BPE codes\n",
        "N_THREADS=22    # number of threads in data preprocessing\n",
        "\n",
        "\n",
        "#\n",
        "# Read arguments\n",
        "#\n",
        "POSITIONAL=()\n",
        "while [[ $# -gt 0 ]]\n",
        "do\n",
        "key=\"$1\"\n",
        "case $key in\n",
        "  --src)\n",
        "    SRC=\"$2\"; shift 2;;\n",
        "  --tgt)\n",
        "    TGT=\"$2\"; shift 2;;\n",
        "  --reload_codes)\n",
        "    RELOAD_CODES=\"$2\"; shift 2;;\n",
        "  --reload_vocab)\n",
        "    RELOAD_VOCAB=\"$2\"; shift 2;;\n",
        "  *)\n",
        "  POSITIONAL+=(\"$1\")\n",
        "  shift\n",
        "  ;;\n",
        "esac\n",
        "done\n",
        "set -- \"${POSITIONAL[@]}\"\n",
        "\n",
        "\n",
        "#\n",
        "# Check parameters\n",
        "#\n",
        "if [ \"$SRC\" == \"\" ]; then echo \"--src not provided\"; exit; fi\n",
        "if [ \"$TGT\" == \"\" ]; then echo \"--tgt not provided\"; exit; fi\n",
        "if [ \"$SRC\" != \"de\" -a \"$SRC\" != \"en\" -a \"$SRC\" != \"fr\" -a \"$SRC\" != \"ro\" ]; then echo \"unknown source language\"; exit; fi\n",
        "if [ \"$TGT\" != \"de\" -a \"$TGT\" != \"en\" -a \"$TGT\" != \"fr\" -a \"$TGT\" != \"ro\" ]; then echo \"unknown target language\"; exit; fi\n",
        "if [ \"$SRC\" == \"$TGT\" ]; then echo \"source and target cannot be identical\"; exit; fi\n",
        "if [ \"$SRC\" \\> \"$TGT\" ]; then echo \"please ensure SRC < TGT\"; exit; fi\n",
        "if [ \"$RELOAD_CODES\" != \"\" ] && [ ! -f \"$RELOAD_CODES\" ]; then echo \"cannot locate BPE codes\"; exit; fi\n",
        "if [ \"$RELOAD_VOCAB\" != \"\" ] && [ ! -f \"$RELOAD_VOCAB\" ]; then echo \"cannot locate vocabulary\"; exit; fi\n",
        "if [ \"$RELOAD_CODES\" == \"\" -a \"$RELOAD_VOCAB\" != \"\" -o \"$RELOAD_CODES\" != \"\" -a \"$RELOAD_VOCAB\" == \"\" ]; then echo \"BPE codes should be provided if and only if vocabulary is also provided\"; exit; fi\n",
        "\n",
        "\n",
        "#\n",
        "# Initialize tools and data paths\n",
        "#\n",
        "\n",
        "# main paths\n",
        "MAIN_PATH=$PWD\n",
        "TOOLS_PATH=$PWD/tools\n",
        "DATA_PATH=$PWD/data\n",
        "MONO_PATH=$DATA_PATH/mono\n",
        "PARA_PATH=$DATA_PATH/para\n",
        "PROC_PATH=$DATA_PATH/processed/$SRC-$TGT\n",
        "\n",
        "# create paths\n",
        "mkdir -p $TOOLS_PATH\n",
        "mkdir -p $DATA_PATH\n",
        "mkdir -p $MONO_PATH\n",
        "mkdir -p $PARA_PATH\n",
        "mkdir -p $PROC_PATH\n",
        "\n",
        "# moses\n",
        "MOSES=$TOOLS_PATH/mosesdecoder\n",
        "REPLACE_UNICODE_PUNCT=$MOSES/scripts/tokenizer/replace-unicode-punctuation.perl\n",
        "NORM_PUNC=$MOSES/scripts/tokenizer/normalize-punctuation.perl\n",
        "REM_NON_PRINT_CHAR=$MOSES/scripts/tokenizer/remove-non-printing-char.perl\n",
        "TOKENIZER=$MOSES/scripts/tokenizer/tokenizer.perl\n",
        "INPUT_FROM_SGM=$MOSES/scripts/ems/support/input-from-sgm.perl\n",
        "\n",
        "# fastBPE\n",
        "FASTBPE_DIR=$TOOLS_PATH/fastBPE\n",
        "FASTBPE=$TOOLS_PATH/fastBPE/fast\n",
        "\n",
        "# raw and tokenized files\n",
        "SRC_RAW=$MONO_PATH/$SRC/all.$SRC\n",
        "TGT_RAW=$MONO_PATH/$TGT/all.$TGT\n",
        "SRC_TOK=$SRC_RAW.tok\n",
        "TGT_TOK=$TGT_RAW.tok\n",
        "\n",
        "# BPE / vocab files\n",
        "BPE_CODES=$PROC_PATH/codes\n",
        "SRC_VOCAB=$PROC_PATH/vocab.$SRC\n",
        "TGT_VOCAB=$PROC_PATH/vocab.$TGT\n",
        "FULL_VOCAB=$PROC_PATH/vocab.$SRC-$TGT\n",
        "\n",
        "# train / valid / test monolingual BPE data\n",
        "SRC_TRAIN_BPE=$PROC_PATH/train.$SRC\n",
        "TGT_TRAIN_BPE=$PROC_PATH/train.$TGT\n",
        "SRC_VALID_BPE=$PROC_PATH/valid.$SRC\n",
        "TGT_VALID_BPE=$PROC_PATH/valid.$TGT\n",
        "SRC_TEST_BPE=$PROC_PATH/test.$SRC\n",
        "TGT_TEST_BPE=$PROC_PATH/test.$TGT\n",
        "\n",
        "# train / valid / test parallel BPE data\n",
        "PARA_SRC_TRAIN_BPE=$PROC_PATH/train.$SRC-$TGT.$SRC\n",
        "PARA_TGT_TRAIN_BPE=$PROC_PATH/train.$SRC-$TGT.$TGT\n",
        "PARA_SRC_VALID_BPE=$PROC_PATH/valid.$SRC-$TGT.$SRC\n",
        "PARA_TGT_VALID_BPE=$PROC_PATH/valid.$SRC-$TGT.$TGT\n",
        "PARA_SRC_TEST_BPE=$PROC_PATH/test.$SRC-$TGT.$SRC\n",
        "PARA_TGT_TEST_BPE=$PROC_PATH/test.$SRC-$TGT.$TGT\n",
        "\n",
        "# train / valid / test file raw data\n",
        "unset PARA_SRC_TRAIN PARA_TGT_TRAIN PARA_SRC_VALID PARA_TGT_VALID PARA_SRC_TEST PARA_TGT_TEST\n",
        "if [ \"$SRC\" == \"en\" -a \"$TGT\" == \"fr\" ]; then\n",
        "  PARA_SRC_TRAIN=/srv/gluster/users/bhardwajs/en_fr_data/data/bt_no_noise_duplicate/new_bt_no_noise_duplicate.en-fr.en\n",
        "  PARA_TGT_TRAIN=/srv/gluster/users/bhardwajs/en_fr_data/data/bt_no_noise_duplicate/new_bt_no_noise_duplicate.en-fr.fr\n",
        "  PARA_SRC_VALID=/srv/gluster/users/bhardwajs/en_fr_data/data/bt_no_noise_duplicate/super_clean_test_valid/bt_valid_no_noise_duplicate.en-fr.en\n",
        "  PARA_TGT_VALID=/srv/gluster/users/bhardwajs/en_fr_data/data/bt_no_noise_duplicate/super_clean_test_valid/bt_valid_no_noise_duplicate.en-fr.fr\n",
        "  PARA_SRC_TEST=/srv/gluster/users/bhardwajs/en_fr_data/data/bt_no_noise_duplicate/super_clean_test_valid/bt_test_no_noise_duplicate.en-fr.en\n",
        "  PARA_TGT_TEST=/srv/gluster/users/bhardwajs/en_fr_data/data/bt_no_noise_duplicate/super_clean_test_valid/bt_test_no_noise_duplicate.en-fr.fr\n",
        "fi\n",
        "\n",
        "\n",
        "#\n",
        "# Download monolingual data\n",
        "#\n",
        "\n",
        "cd $MONO_PATH\n",
        "\n",
        "if [ \"$SRC\" == \"en\" -o \"$TGT\" == \"en\" ]; then\n",
        "  echo \"Downloading English monolingual data ...\"\n",
        "  mkdir -p $MONO_PATH/en\n",
        "  cd $MONO_PATH/en\n",
        "  wget -c http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2007.en.shuffled.gz\n",
        "  wget -c http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2008.en.shuffled.gz\n",
        "fi\n",
        "\n",
        "if [ \"$SRC\" == \"fr\" -o \"$TGT\" == \"fr\" ]; then\n",
        "  echo \"Downloading French monolingual data ...\"\n",
        "  mkdir -p $MONO_PATH/fr\n",
        "  cd $MONO_PATH/fr\n",
        "  wget -c http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2007.fr.shuffled.gz\n",
        "  wget -c http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2008.fr.shuffled.gz\n",
        "  wget -c http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2009.fr.shuffled.gz\n",
        "fi\n",
        "\n",
        "cd $MONO_PATH\n",
        "\n",
        "# decompress monolingual data\n",
        "for FILENAME in $SRC/news*gz $TGT/news*gz; do\n",
        "  OUTPUT=\"${FILENAME::-3}\"\n",
        "  if [ ! -f \"$OUTPUT\" ]; then\n",
        "    echo \"Decompressing $FILENAME...\"\n",
        "    gunzip -k $FILENAME\n",
        "  else\n",
        "    echo \"$OUTPUT already decompressed.\"\n",
        "  fi\n",
        "done\n",
        "\n",
        "# concatenate monolingual data files\n",
        "if ! [[ -f \"$SRC_RAW\" ]]; then\n",
        "  echo \"Concatenating $SRC monolingual data...\"\n",
        "  cat $(ls $SRC/news*$SRC* | grep -v gz) | head -n $N_MONO > $SRC_RAW\n",
        "fi\n",
        "if ! [[ -f \"$TGT_RAW\" ]]; then\n",
        "  echo \"Concatenating $TGT monolingual data...\"\n",
        "  cat $(ls $TGT/news*$TGT* | grep -v gz) | head -n $N_MONO > $TGT_RAW\n",
        "fi\n",
        "echo \"$SRC monolingual data concatenated in: $SRC_RAW\"\n",
        "echo \"$TGT monolingual data concatenated in: $TGT_RAW\"\n",
        "\n",
        "# install tools\n",
        "./install-tools.sh\n",
        "\n",
        "SRC_PREPROCESSING=\"$REPLACE_UNICODE_PUNCT | $NORM_PUNC -l $SRC | $REM_NON_PRINT_CHAR | $TOKENIZER -l $SRC -no-escape -threads $N_THREADS\"\n",
        "TGT_PREPROCESSING=\"$REPLACE_UNICODE_PUNCT | $NORM_PUNC -l $TGT | $REM_NON_PRINT_CHAR | $TOKENIZER -l $TGT -no-escape -threads $N_THREADS\"\n",
        "\n",
        "\n",
        "# tokenize data\n",
        "if ! [[ -f \"$SRC_TOK\" ]]; then\n",
        "  echo \"Tokenize $SRC monolingual data...\"\n",
        "  eval \"cat $SRC_RAW | $SRC_PREPROCESSING > $SRC_TOK\"\n",
        "fi\n",
        "\n",
        "if ! [[ -f \"$TGT_TOK\" ]]; then\n",
        "  echo \"Tokenize $TGT monolingual data...\"\n",
        "  eval \"cat $TGT_RAW | $TGT_PREPROCESSING > $TGT_TOK\"\n",
        "fi\n",
        "echo \"$SRC monolingual data tokenized in: $SRC_TOK\"\n",
        "echo \"$TGT monolingual data tokenized in: $TGT_TOK\"\n",
        "\n",
        "\n",
        "echo \"Tokenizing training data...\"\n",
        "\n",
        "eval \"cat $PARA_SRC_TRAIN | $SRC_PREPROCESSING > $PARA_SRC_TRAIN.all\"\n",
        "eval \"cat $PARA_TGT_TRAIN | $TGT_PREPROCESSING > $PARA_TGT_TRAIN.all\"\n",
        "\n",
        "\n",
        "# reload BPE codes\n",
        "cd $MAIN_PATH\n",
        "if [ ! -f \"$BPE_CODES\" ] && [ -f \"$RELOAD_CODES\" ]; then\n",
        "  echo \"Reloading BPE codes from $RELOAD_CODES ...\"\n",
        "  cp $RELOAD_CODES $BPE_CODES\n",
        "fi\n",
        "\n",
        "# learn BPE codes\n",
        "if [ ! -f \"$BPE_CODES\" ]; then\n",
        "  echo \"Learning BPE codes...\"\n",
        "  $FASTBPE learnbpe $CODES $PARA_SRC_TRAIN.all $PARA_TGT_TRAIN.all > $BPE_CODES\n",
        "fi\n",
        "echo \"BPE learned in $BPE_CODES\"\n",
        "\n",
        "\n",
        "# apply BPE codes\n",
        "if ! [[ -f \"$SRC_TRAIN_BPE\" ]]; then\n",
        "  echo \"Applying $SRC BPE codes...\"\n",
        "  $FASTBPE applybpe $SRC_TRAIN_BPE $SRC_TOK $BPE_CODES\n",
        "fi\n",
        "if ! [[ -f \"$TGT_TRAIN_BPE\" ]]; then\n",
        "  echo \"Applying $TGT BPE codes...\"\n",
        "  $FASTBPE applybpe $TGT_TRAIN_BPE $TGT_TOK $BPE_CODES\n",
        "fi\n",
        "echo \"BPE codes applied to $SRC in: $SRC_TRAIN_BPE\"\n",
        "echo \"BPE codes applied to $TGT in: $TGT_TRAIN_BPE\"\n",
        "\n",
        "\n",
        "echo \"Applying BPE to training files...\"\n",
        "\n",
        "# apply BPE codes\n",
        "if ! [[ -f \"$PARA_SRC_TRAIN_BPE\" ]]; then\n",
        "  echo \"Applying $SRC BPE codes...\"\n",
        "  $FASTBPE applybpe $PARA_SRC_TRAIN_BPE $PARA_SRC_TRAIN.all $BPE_CODES\n",
        "fi\n",
        "if ! [[ -f \"$PARA_TGT_TRAIN_BPE\" ]]; then\n",
        "  echo \"Applying $TGT BPE codes...\"\n",
        "  $FASTBPE applybpe $PARA_TGT_TRAIN_BPE $PARA_TGT_TRAIN.all $BPE_CODES\n",
        "fi\n",
        "echo \"BPE codes applied to $SRC in: $PARA_SRC_TRAIN_BPE\"\n",
        "echo \"BPE codes applied to $TGT in: $PARA_TGT_TRAIN_BPE\"\n",
        "\n",
        "\n",
        "echo \"Binarizing data...\"\n",
        "rm -f $PARA_SRC_TRAIN_BPE.pth $PARA_TGT_TRAIN_BPE.pth $PARA_SRC_VALID_BPE.pth $PARA_TGT_VALID_BPE.pth $PARA_SRC_TEST_BPE.pth $PARA_TGT_TEST_BPE.pth\n",
        "\n",
        "\n",
        "# extract source and target vocabulary\n",
        "if ! [[ -f \"$SRC_VOCAB\" && -f \"$TGT_VOCAB\" ]]; then\n",
        "  echo \"Extracting vocabulary...\"\n",
        "  $FASTBPE getvocab $PARA_SRC_TRAIN_BPE > $SRC_VOCAB\n",
        "  $FASTBPE getvocab $PARA_TGT_TRAIN_BPE > $TGT_VOCAB\n",
        "fi\n",
        "echo \"$SRC vocab in: $SRC_VOCAB\"\n",
        "echo \"$TGT vocab in: $TGT_VOCAB\"\n",
        "\n",
        "# reload full vocabulary\n",
        "cd $MAIN_PATH\n",
        "if [ ! -f \"$FULL_VOCAB\" ] && [ -f \"$RELOAD_VOCAB\" ]; then\n",
        "  echo \"Reloading vocabulary from $RELOAD_VOCAB ...\"\n",
        "  cp $RELOAD_VOCAB $FULL_VOCAB\n",
        "fi\n",
        "\n",
        "# extract full vocabulary\n",
        "if ! [[ -f \"$FULL_VOCAB\" ]]; then\n",
        "  echo \"Extracting vocabulary...\"\n",
        "  $FASTBPE getvocab $PARA_SRC_TRAIN_BPE $PARA_TGT_TRAIN_BPE > $FULL_VOCAB\n",
        "fi\n",
        "echo \"Full vocab in: $FULL_VOCAB\"\n",
        "\n",
        "# binarize data\n",
        "if ! [[ -f \"$SRC_TRAIN_BPE.pth\" ]]; then\n",
        "  echo \"Binarizing $SRC data...\"\n",
        "  $MAIN_PATH/preprocess.py $FULL_VOCAB $SRC_TRAIN_BPE\n",
        "fi\n",
        "if ! [[ -f \"$TGT_TRAIN_BPE.pth\" ]]; then\n",
        "  echo \"Binarizing $TGT data...\"\n",
        "  $MAIN_PATH/preprocess.py $FULL_VOCAB $TGT_TRAIN_BPE\n",
        "fi\n",
        "echo \"$SRC binarized data in: $SRC_TRAIN_BPE.pth\"\n",
        "echo \"$TGT binarized data in: $TGT_TRAIN_BPE.pth\"\n",
        "\n",
        "\n",
        "cd $PARA_PATH\n",
        "\n",
        "echo \"Tokenizing valid and test data...\"\n",
        "\n",
        "eval \"cat $PARA_SRC_VALID | $SRC_PREPROCESSING > $PARA_SRC_VALID.all\"\n",
        "eval \"cat $PARA_TGT_VALID | $TGT_PREPROCESSING > $PARA_TGT_VALID.all\"\n",
        "eval \"cat $PARA_SRC_TEST  | $SRC_PREPROCESSING > $PARA_SRC_TEST.all\"\n",
        "eval \"cat $PARA_TGT_TEST  | $TGT_PREPROCESSING > $PARA_TGT_TEST.all\"\n",
        "\n",
        "echo \"Applying BPE to valid and test files...\"\n",
        "\n",
        "#EDIT:\n",
        "\n",
        "$FASTBPE applybpe $PARA_SRC_VALID_BPE $PARA_SRC_VALID.all $BPE_CODES $SRC_VOCAB\n",
        "$FASTBPE applybpe $PARA_TGT_VALID_BPE $PARA_TGT_VALID.all $BPE_CODES $TGT_VOCAB\n",
        "$FASTBPE applybpe $PARA_SRC_TEST_BPE  $PARA_SRC_TEST.all  $BPE_CODES $SRC_VOCAB\n",
        "$FASTBPE applybpe $PARA_TGT_TEST_BPE  $PARA_TGT_TEST.all  $BPE_CODES $TGT_VOCAB\n",
        "\n",
        "\n",
        "# binarize data\n",
        "if ! [[ -f \"$PARA_SRC_TRAIN_BPE.pth\" ]]; then\n",
        "  echo \"Binarizing $SRC data...\"\n",
        "  $MAIN_PATH/preprocess.py $FULL_VOCAB $PARA_SRC_TRAIN_BPE\n",
        "fi\n",
        "if ! [[ -f \"$PARA_TGT_TRAIN_BPE.pth\" ]]; then\n",
        "  echo \"Binarizing $TGT data...\"\n",
        "  $MAIN_PATH/preprocess.py $FULL_VOCAB $PARA_TGT_TRAIN_BPE\n",
        "fi\n",
        "echo \"$SRC binarized data in: $PARA_SRC_TRAIN_BPE.pth\"\n",
        "echo \"$TGT binarized data in: $PARA_TGT_TRAIN_BPE.pth\"\n",
        "\n",
        "$MAIN_PATH/preprocess.py $FULL_VOCAB $PARA_SRC_VALID_BPE\n",
        "$MAIN_PATH/preprocess.py $FULL_VOCAB $PARA_TGT_VALID_BPE\n",
        "$MAIN_PATH/preprocess.py $FULL_VOCAB $PARA_SRC_TEST_BPE\n",
        "$MAIN_PATH/preprocess.py $FULL_VOCAB $PARA_TGT_TEST_BPE\n",
        "\n",
        "\n",
        "#\n",
        "# Summary\n",
        "#\n",
        "echo \"\"\n",
        "echo \"===== Data summary\"\n",
        "\n",
        "echo \"Monolingual training data:\"\n",
        "echo \"    $SRC: $SRC_TRAIN_BPE.pth\"\n",
        "echo \"    $TGT: $TGT_TRAIN_BPE.pth\"\n",
        "echo \"Monolingual validation data:\"\n",
        "echo \"    $SRC: $SRC_VALID_BPE.pth\"\n",
        "echo \"    $TGT: $TGT_VALID_BPE.pth\"\n",
        "echo \"Monolingual test data:\"\n",
        "echo \"    $SRC: $SRC_TEST_BPE.pth\"\n",
        "echo \"    $TGT: $TGT_TEST_BPE.pth\"\n",
        "\n",
        "echo \"Parallel validation data:\"\n",
        "echo \"    $SRC: $PARA_SRC_TRAIN_BPE.pth\"\n",
        "echo \"    $TGT: $PARA_TGT_TRAIN_BPE.pth\"\n",
        "echo \"Parallel validation data:\"\n",
        "echo \"    $SRC: $PARA_SRC_VALID_BPE.pth\"\n",
        "echo \"    $TGT: $PARA_TGT_VALID_BPE.pth\"\n",
        "echo \"Parallel test data:\"\n",
        "echo \"    $SRC: $PARA_SRC_TEST_BPE.pth\"\n",
        "echo \"    $TGT: $PARA_TGT_TEST_BPE.pth\"\n",
        "echo \"\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}